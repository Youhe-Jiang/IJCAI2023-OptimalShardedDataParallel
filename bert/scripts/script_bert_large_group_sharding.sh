torchrun --nproc_per_node=4 --master_port 9999 train_bert_large_group_sharding.py \
--train_batch_size 1 \
--vocab_size 30522 \
--hidden_size 1024 \
--num_hidden_layers 24 \
--num_attention_heads 16 \
--seq_length 512 \
--epochs 10 \
--lr 1e-4 \
--adam_weight_decay 0.01 \
--dropout_prob 0.1 \
--profile 1 \
--check_loss 0
